{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinJayne2023/agent_recruiter_screening_langgraph/blob/main/agent_recruiter_screening_langgraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ade998c-79b2-4af5-9207-034e92bb9fcc"
      },
      "source": [
        "# Recruiter Screening Notes — LangChain + LangGraph\n",
        "\n",
        "Paste raw screening-call notes → get polished **Screening Notes** (Markdown) and **5 job title suggestions** with rationales.\n",
        "\n",
        "**What this notebook does**\n",
        "- Extracts structured data from messy notes (name, experience, skills, comp, risks...)\n",
        "- Normalizes skills\n",
        "- Suggests 5 job titles with brief rationales\n",
        "- Produces a final Markdown summary + JSON payload you can paste to your ATS/CRM\n",
        "\n",
        "**Stack**: LangChain, LangGraph, OpenAI (or swap model), Pydantic, RapidFuzz\n"
      ],
      "id": "8ade998c-79b2-4af5-9207-034e92bb9fcc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Install Dependencies"
      ],
      "metadata": {
        "id": "BQD3U0u7LcFV"
      },
      "id": "BQD3U0u7LcFV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1703e5e2-71fc-4568-89b4-661c85c721f6"
      },
      "source": [
        "!pip -q install \"langchain>=0.2.10\" \"langgraph>=0.2.20\" \"langchain-openai>=0.1.20\" \"pydantic>=2.7.0\" \"rapidfuzz>=3.7.0\" \"python-dotenv>=1.0.1\""
      ],
      "execution_count": null,
      "outputs": [],
      "id": "1703e5e2-71fc-4568-89b4-661c85c721f6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29a36060-5826-4cc3-bef3-2fcfdee214c4"
      },
      "source": [
        "## 2) Configure API key"
      ],
      "id": "29a36060-5826-4cc3-bef3-2fcfdee214c4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbcd60e1-20d9-4bd4-8897-3386abc63b2c"
      },
      "source": [
        "import os, getpass\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    try:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OPENAI_API_KEY (input hidden): \")\n",
        "    except Exception as e:\n",
        "        print(\"You can also set it manually: os.environ['OPENAI_API_KEY'] = 'sk-...' \")\n",
        "print(\"API key set:\", bool(os.environ.get(\"OPENAI_API_KEY\")))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "dbcd60e1-20d9-4bd4-8897-3386abc63b2c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "461f5dc2-de7c-4e8b-aed5-39b86e493152"
      },
      "source": [
        "## 3) Define models, helpers, and ontology"
      ],
      "id": "461f5dc2-de7c-4e8b-aed5-39b86e493152"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8239631-9245-4409-9a4c-eaf073a32fdf"
      },
      "source": [
        "from __future__ import annotations\n",
        "from typing import List, Optional, Dict, Any, TypedDict\n",
        "from dataclasses import dataclass\n",
        "from pydantic import BaseModel, Field\n",
        "import os, re, json\n",
        "from rapidfuzz import fuzz\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langgraph.graph import StateGraph, END\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "class ExperienceItem(BaseModel):\n",
        "    title: Optional[str] = None\n",
        "    company: Optional[str] = None\n",
        "    start: Optional[str] = None\n",
        "    end: Optional[str] = None\n",
        "    highlights: List[str] = Field(default_factory=list)\n",
        "\n",
        "class ScreeningExtraction(BaseModel):\n",
        "    candidate_name: Optional[str] = None\n",
        "    current_title: Optional[str] = None\n",
        "    current_company: Optional[str] = None\n",
        "    years_experience: Optional[float] = None\n",
        "    location: Optional[str] = None\n",
        "    work_authorization: Optional[str] = None\n",
        "    remote_on_site_pref: Optional[str] = None\n",
        "    comp_current: Optional[str] = None\n",
        "    comp_expected: Optional[str] = None\n",
        "    notice_period: Optional[str] = None\n",
        "    earliest_start_date: Optional[str] = None\n",
        "    role_preferences: List[str] = Field(default_factory=list)\n",
        "    top_skills: List[str] = Field(default_factory=list)\n",
        "    tools_stack: List[str] = Field(default_factory=list)\n",
        "    industries: List[str] = Field(default_factory=list)\n",
        "    risk_flags: List[str] = Field(default_factory=list)\n",
        "    notable_quotes: List[str] = Field(default_factory=list)\n",
        "    experience: List[ExperienceItem] = Field(default_factory=list)\n",
        "    summary_paragraph: Optional[str] = None\n",
        "\n",
        "class TitleSuggestion(BaseModel):\n",
        "    title: str\n",
        "    rationale: str\n",
        "    confidence: float = Field(ge=0, le=1)\n",
        "\n",
        "class ScreenState(TypedDict, total=False):\n",
        "    raw_notes: str\n",
        "    cleaned_notes: str\n",
        "    extracted: ScreeningExtraction\n",
        "    normalized_skills: List[str]\n",
        "    title_suggestions: List[TitleSuggestion]\n",
        "    formatted_markdown: str\n",
        "    json_payload: Dict[str, Any]\n",
        "\n",
        "def make_llm(model: str = \"gpt-4o-mini\", temperature: float = 0.1):\n",
        "    return ChatOpenAI(model=model, temperature=temperature)\n",
        "\n",
        "def normalize_text(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
        "\n",
        "# --- Canonical skills ---\n",
        "CANONICAL_SKILLS = {\n",
        "    \"python\": [\"py\", \"python3\"],\n",
        "    \"java\": [],\n",
        "    \"javascript\": [\"js\", \"ecmascript\"],\n",
        "    \"typescript\": [\"ts\"],\n",
        "    \"react\": [\"reactjs\", \"react.js\"],\n",
        "    \"node\": [\"nodejs\", \"node.js\"],\n",
        "    \"sql\": [],\n",
        "    \"aws\": [\"amazon web services\"],\n",
        "    \"gcp\": [\"google cloud\"],\n",
        "    \"azure\": [],\n",
        "    \"docker\": [],\n",
        "    \"kubernetes\": [\"k8s\", \"kube\"],\n",
        "    \"spark\": [\"pyspark\"],\n",
        "    \"hadoop\": [],\n",
        "    \"airflow\": [],\n",
        "    \"terraform\": [],\n",
        "    \"ci/cd\": [\"cicd\", \"ci cd\"],\n",
        "    # data/ml\n",
        "    \"pandas\": [],\n",
        "    \"numpy\": [],\n",
        "    \"pytorch\": [],\n",
        "    \"tensorflow\": [\"tf\", \"tfx\"],\n",
        "    \"sklearn\": [\"scikit-learn\"],\n",
        "    \"mlops\": [\"sagemaker\", \"vertex ai\", \"mlflow\"],\n",
        "    \"nlp\": [\"natural language processing\"],\n",
        "    \"computer vision\": [\"cv\"],\n",
        "    \"llm\": [\"large language model\", \"gpt\", \"llama\"],\n",
        "    # RAG / LLM tooling\n",
        "    \"langchain\": [],\n",
        "    \"langgraph\": [],\n",
        "    \"prompt engineering\": [\"prompting\", \"system prompt\", \"few-shot\"],\n",
        "    \"rag\": [\"retrieval-augmented generation\", \"retrieval\"],\n",
        "    \"faiss\": [],\n",
        "    \"pgvector\": [],\n",
        "    \"pinecone\": [],\n",
        "    \"openai\": [],\n",
        "    \"anthropic\": [],\n",
        "    # analytics / data tools\n",
        "    \"dbt\": [],\n",
        "    # sre/devops\n",
        "    \"prometheus\": [],\n",
        "    \"grafana\": [],\n",
        "    # qa/security\n",
        "    \"selenium\": [],\n",
        "    \"cypress\": [],\n",
        "    \"pytest\": [],\n",
        "    \"security\": [],\n",
        "    \"iam\": [],\n",
        "    \"kms\": [],\n",
        "    \"siem\": [],\n",
        "}\n",
        "\n",
        "TITLE_ONTOLOGY = [\n",
        "    \"Software Engineer (Backend)\",\n",
        "    \"Software Engineer (Frontend)\",\n",
        "    \"Full-Stack Engineer\",\n",
        "    \"Data Engineer\",\n",
        "    \"Machine Learning Engineer\",\n",
        "    \"MLOps Engineer\",\n",
        "    \"Data Scientist\",\n",
        "    \"Analytics Engineer\",\n",
        "    \"DevOps Engineer\",\n",
        "    \"Site Reliability Engineer (SRE)\",\n",
        "    \"QA Automation Engineer\",\n",
        "    \"Security Engineer\",\n",
        "    \"Solutions Architect\",\n",
        "    \"Product Manager (Technical)\",\n",
        "    \"AI Engineer\",\n",
        "    \"Prompt Engineer\",\n",
        "]\n",
        "\n",
        "TITLE_KEYWORDS = {\n",
        "    \"Software Engineer (Backend)\": [\"python\", \"java\", \"node\", \"sql\", \"aws\", \"gcp\", \"docker\", \"kubernetes\"],\n",
        "    \"Software Engineer (Frontend)\": [\"javascript\", \"typescript\", \"react\"],\n",
        "    \"Full-Stack Engineer\": [\"react\", \"node\", \"python\", \"typescript\"],\n",
        "    \"Data Engineer\": [\"spark\", \"airflow\", \"python\", \"sql\", \"hadoop\", \"aws\"],\n",
        "    \"Machine Learning Engineer\": [\"pytorch\", \"tensorflow\", \"sklearn\", \"mlops\", \"llm\", \"nlp\", \"computer vision\"],\n",
        "    \"MLOps Engineer\": [\"mlops\", \"kubernetes\", \"docker\", \"aws\", \"gcp\", \"mlflow\", \"sagemaker\", \"vertex ai\"],\n",
        "    \"Data Scientist\": [\"python\", \"pandas\", \"numpy\", \"sklearn\", \"nlp\", \"llm\"],\n",
        "    \"Analytics Engineer\": [\"sql\", \"dbt\", \"warehouse\", \"etl\", \"airflow\"],\n",
        "    \"DevOps Engineer\": [\"aws\", \"gcp\", \"azure\", \"kubernetes\", \"docker\", \"terraform\", \"ci/cd\"],\n",
        "    \"Site Reliability Engineer (SRE)\": [\"kubernetes\", \"observability\", \"prometheus\", \"grafana\", \"incident\"],\n",
        "    \"QA Automation Engineer\": [\"selenium\", \"cypress\", \"pytest\"],\n",
        "    \"Security Engineer\": [\"security\", \"iam\", \"kms\", \"siem\"],\n",
        "    \"Solutions Architect\": [\"pre-sales\", \"solutions\", \"customer\", \"cloud\", \"architecture\"],\n",
        "    \"Product Manager (Technical)\": [\"product\", \"requirements\", \"backlog\", \"roadmap\", \"stakeholder\"],\n",
        "    \"AI Engineer\": [\n",
        "        \"llm\", \"rag\", \"langchain\", \"langgraph\", \"embeddings\", \"vector\", \"faiss\", \"pgvector\",\n",
        "        \"pinecone\", \"openai\", \"anthropic\", \"function calling\", \"tools\", \"agents\", \"retrieval\",\n",
        "        \"guardrails\", \"evaluation\", \"observability\", \"python\", \"pydantic\"\n",
        "    ],\n",
        "    \"Prompt Engineer\": [\n",
        "        \"prompt\", \"few-shot\", \"system prompt\", \"templates\", \"structured output\", \"json\",\n",
        "        \"function calling\", \"tools\", \"eval\", \"evaluation\", \"guardrail\", \"jailbreak\",\n",
        "        \"injection\", \"rag\", \"retrieval\", \"langchain\", \"langgraph\", \"rubrics\", \"A/B\"\n",
        "    ],\n",
        "}\n",
        "\n",
        "def normalize_skills(skills: List[str]) -> List[str]:\n",
        "    canon = set()\n",
        "    for raw in skills:\n",
        "        if not raw:\n",
        "            continue\n",
        "        low = raw.lower().strip()\n",
        "        hit = False\n",
        "        for key, aliases in CANONICAL_SKILLS.items():\n",
        "            if low == key or low in aliases:\n",
        "                canon.add(key)\n",
        "                hit = True\n",
        "                break\n",
        "        if hit:\n",
        "            continue\n",
        "        best = None\n",
        "        best_score = 0\n",
        "        for key, aliases in CANONICAL_SKILLS.items():\n",
        "            for term in [key] + aliases:\n",
        "                score = fuzz.partial_ratio(low, term)\n",
        "                if score > best_score:\n",
        "                    best, best_score = key, score\n",
        "        if best and best_score >= 85:\n",
        "            canon.add(best)\n",
        "        else:\n",
        "            canon.add(raw)\n",
        "    return sorted(canon)\n",
        "\n",
        "def score_titles(skills: List[str], text_blob: str) -> List[tuple[str, float]]:\n",
        "    low_text = text_blob.lower()\n",
        "    scores = []\n",
        "    skillset = set([s.lower() for s in skills])\n",
        "    for title in TITLE_ONTOLOGY:\n",
        "        kws = TITLE_KEYWORDS.get(title, [])\n",
        "        hit_skill = len(skillset.intersection(set(kws)))\n",
        "        hit_text = sum(1 for k in kws if k in low_text)\n",
        "        score = hit_skill * 1.0 + hit_text * 0.5\n",
        "        scores.append((title, score))\n",
        "    scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    return scores\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d8239631-9245-4409-9a4c-eaf073a32fdf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64b3bbb3-c118-4457-8cd5-516347ff1a03"
      },
      "source": [
        "## 4) Build the LangGraph and nodes"
      ],
      "id": "64b3bbb3-c118-4457-8cd5-516347ff1a03"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9449b7c1-4fa7-474e-88c7-680d05052dc1"
      },
      "source": [
        "def preprocess_node(state: ScreenState) -> ScreenState:\n",
        "    notes = state.get(\"raw_notes\", \"\")\n",
        "    cleaned = normalize_text(notes)\n",
        "    return {\"cleaned_notes\": cleaned}\n",
        "\n",
        "def extract_node(state: ScreenState) -> ScreenState:\n",
        "    llm = make_llm()\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\",\n",
        "         \"You are a meticulous recruiter’s assistant. Extract structured fields from the call notes. \"\n",
        "         \"If a field is unknown, leave it null or empty. Do not invent facts.\"),\n",
        "        (\"human\",\n",
        "         \"Call notes:\\n\\n{notes}\\n\\n\"\n",
        "         \"Return ONLY a JSON object matching this Pydantic schema:\\n\"\n",
        "         f\"{ScreeningExtraction.schema_json(indent=2)}\")\n",
        "    ])\n",
        "    chain = prompt | llm.with_structured_output(ScreeningExtraction)\n",
        "    extracted: ScreeningExtraction = chain.invoke({\"notes\": state[\"cleaned_notes\"]})\n",
        "    return {\"extracted\": extracted}\n",
        "\n",
        "def normalize_skills_node(state: ScreenState) -> ScreenState:\n",
        "    extracted: ScreeningExtraction = state[\"extracted\"]\n",
        "    combined = list({*(extracted.top_skills or []), *(extracted.tools_stack or [])})\n",
        "    norm = normalize_skills(combined)\n",
        "    return {\"normalized_skills\": norm}\n",
        "\n",
        "def suggest_titles_node(state: ScreenState) -> ScreenState:\n",
        "    extracted: ScreeningExtraction = state[\"extracted\"]\n",
        "    skills = state.get(\"normalized_skills\", [])\n",
        "    text_blob = \" \".join([\n",
        "        state.get(\"cleaned_notes\", \"\"),\n",
        "        \" \".join(skills),\n",
        "        extracted.summary_paragraph or \"\",\n",
        "        (extracted.current_title or \"\") + \" \" + \" \".join(extracted.role_preferences or [])\n",
        "    ])\n",
        "    base_scores = score_titles(skills, text_blob)\n",
        "    top8 = [t for t, s in base_scores[:8] if s > 0] or [t for t, _ in base_scores[:8]]\n",
        "    llm = make_llm(temperature=0.2)\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"You propose 5 job titles a candidate fits and explain why. Calibrate confidence 0.6–0.95.\"),\n",
        "        (\"human\",\n",
        "         \"Candidate context (JSON):\\n\"\n",
        "         f\"{state['extracted'].json()}\\n\\n\"\n",
        "         f\"Normalized skills: {skills}\\n\"\n",
        "         f\"Title candidates to choose from: {top8}\\n\\n\"\n",
        "         \"Return a JSON array of objects {title, rationale, confidence} (5 items).\")\n",
        "    ])\n",
        "    parser = StrOutputParser()\n",
        "    raw = (prompt | llm | parser).invoke({})\n",
        "    try:\n",
        "        parsed = json.loads(raw)\n",
        "        suggestions = [TitleSuggestion(**d) for d in parsed][:5]\n",
        "    except Exception:\n",
        "        suggestions = [\n",
        "            TitleSuggestion(title=t, rationale=\"Matches skill keywords and experience signals.\", confidence=0.7)\n",
        "            for t, _ in base_scores[:5]\n",
        "        ]\n",
        "    return {\"title_suggestions\": suggestions}\n",
        "\n",
        "def format_markdown_node(state: ScreenState) -> ScreenState:\n",
        "    e: ScreeningExtraction = state[\"extracted\"]\n",
        "    titles: List[TitleSuggestion] = state[\"title_suggestions\"]\n",
        "    skills = \", \".join(state.get(\"normalized_skills\", []))\n",
        "\n",
        "    md = []\n",
        "    md.append(f\"# Screening Notes — {e.candidate_name or 'Candidate'}\")\n",
        "    md.append(\"\")\n",
        "    md.append(\"## Overview\")\n",
        "    md.append(e.summary_paragraph or \"—\")\n",
        "    md.append(\"\")\n",
        "    md.append(\"## Snapshot\")\n",
        "    md.append(f\"- **Current Title/Company:** {e.current_title or '—'} @ {e.current_company or '—'}\")\n",
        "    md.append(f\"- **Location:** {e.location or '—'}\")\n",
        "    md.append(f\"- **Years Experience:** {e.years_experience if e.years_experience is not None else '—'}\")\n",
        "    md.append(f\"- **Work Authorization:** {e.work_authorization or '—'}\")\n",
        "    md.append(f\"- **Work Preference:** {e.remote_on_site_pref or '—'}\")\n",
        "    md.append(f\"- **Comp (Current):** {e.comp_current or '—'}\")\n",
        "    md.append(f\"- **Comp (Expected):** {e.comp_expected or '—'}\")\n",
        "    md.append(f\"- **Notice / Availability:** {e.notice_period or '—'} / {e.earliest_start_date or '—'}\")\n",
        "    md.append(\"\")\n",
        "    md.append(\"## Role Preferences\")\n",
        "    md.append((\"; \".join(e.role_preferences)) if e.role_preferences else \"—\")\n",
        "    md.append(\"\")\n",
        "    md.append(\"## Skills & Stack\")\n",
        "    md.append(skills or \"—\")\n",
        "    md.append(\"\")\n",
        "    if e.experience:\n",
        "        md.append(\"## Experience Highlights\")\n",
        "        for item in e.experience:\n",
        "            line = f\"- **{item.title or '—'}**, {item.company or '—'}\"\n",
        "            if item.start or item.end:\n",
        "                line += f\" ({item.start or ''}–{item.end or ''})\"\n",
        "            md.append(line)\n",
        "            for h in (item.highlights or []):\n",
        "                md.append(f\"  - {h}\")\n",
        "        md.append(\"\")\n",
        "    if e.risk_flags:\n",
        "        md.append(\"## Risks / Concerns\")\n",
        "        for r in e.risk_flags:\n",
        "            md.append(f\"- {r}\")\n",
        "        md.append(\"\")\n",
        "    if e.notable_quotes:\n",
        "        md.append(\"## Notable Quotes\")\n",
        "        for q in e.notable_quotes:\n",
        "            md.append(f\"> {q}\")\n",
        "        md.append(\"\")\n",
        "    md.append(\"## Suggested Job Titles (Top 5)\")\n",
        "    for i, t in enumerate(titles[:5], 1):\n",
        "        md.append(f\"{i}. **{t.title}** — {t.rationale} _(confidence: {t.confidence:.2f})_\")\n",
        "\n",
        "    payload = {\n",
        "        \"extracted\": json.loads(e.json()),\n",
        "        \"normalized_skills\": state.get(\"normalized_skills\", []),\n",
        "        \"title_suggestions\": [t.dict() for t in titles[:5]],\n",
        "    }\n",
        "    return {\"formatted_markdown\": \"\\n\".join(md), \"json_payload\": payload}\n",
        "\n",
        "def build_graph():\n",
        "    sg = StateGraph(ScreenState)\n",
        "    sg.add_node(\"preprocess\", preprocess_node)\n",
        "    sg.add_node(\"extract\", extract_node)\n",
        "    sg.add_node(\"normalize_skills\", normalize_skills_node)\n",
        "    sg.add_node(\"suggest_titles\", suggest_titles_node)\n",
        "    sg.add_node(\"format_markdown\", format_markdown_node)\n",
        "    sg.set_entry_point(\"preprocess\")\n",
        "    sg.add_edge(\"preprocess\", \"extract\")\n",
        "    sg.add_edge(\"extract\", \"normalize_skills\")\n",
        "    sg.add_edge(\"normalize_skills\", \"suggest_titles\")\n",
        "    sg.add_edge(\"suggest_titles\", \"format_markdown\")\n",
        "    sg.add_edge(\"format_markdown\", END)\n",
        "    return sg.compile()\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "9449b7c1-4fa7-474e-88c7-680d05052dc1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01fab2f9-ce72-46fa-b2ae-6b4fba2cabc7"
      },
      "source": [
        "## 5) Paste your call notes and run\n",
        "Enter redacted notes below"
      ],
      "id": "01fab2f9-ce72-46fa-b2ae-6b4fba2cabc7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e699bf2-3ff3-4666-ac85-97b46c750a24"
      },
      "source": [
        "RAW_NOTES = \"\"\"\n",
        "Add notes here\n",
        "\"\"\".strip()\n",
        "print(RAW_NOTES[:1000] + (\"...\" if len(RAW_NOTES)>1000 else \"\"))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "2e699bf2-3ff3-4666-ac85-97b46c750a24"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ce0de65-de8c-420a-a14d-faf4e0c88beb"
      },
      "source": [
        "## 6) Run the graph -> View results (Markdown + JSON)"
      ],
      "id": "7ce0de65-de8c-420a-a14d-faf4e0c88beb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f03f3fa-3332-4cf7-8a38-a4d69d3b6222"
      },
      "source": [
        "graph = build_graph()\n",
        "out = graph.invoke({\"raw_notes\": RAW_NOTES})\n",
        "md = out[\"formatted_markdown\"]\n",
        "payload = out[\"json_payload\"]\n",
        "display(Markdown(md))\n",
        "print(\"\\n--- JSON payload ---\\n\")\n",
        "print(json.dumps(payload, indent=2))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "5f03f3fa-3332-4cf7-8a38-a4d69d3b6222"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "304aabbe-a9a4-4024-bf7b-6201e81efa5c"
      },
      "source": [
        "## 7) Save to files\n",
        "Saves Markdown and JSON to `/content/`. You can also upload them to your ATS."
      ],
      "id": "304aabbe-a9a4-4024-bf7b-6201e81efa5c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5c5acc7-5cd7-4319-9826-0a4dcdc5b803"
      },
      "source": [
        "from pathlib import Path\n",
        "Path('/content').mkdir(parents=True, exist_ok=True)\n",
        "md_path = '/content/screening_notes.md'\n",
        "json_path = '/content/screening_payload.json'\n",
        "with open(md_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(md)\n",
        "with open(json_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(payload, f, indent=2)\n",
        "print('Saved:', md_path)\n",
        "print('Saved:', json_path)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "a5c5acc7-5cd7-4319-9826-0a4dcdc5b803"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RN-0ymmPMnrO"
      },
      "id": "RN-0ymmPMnrO",
      "execution_count": null,
      "outputs": []
    }
  ]
}